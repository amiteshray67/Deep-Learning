{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Details\n",
    "\n",
    "Trains a simple convnet on the CIFAR10 dataset for ONLY cats and dogs.\n",
    "The focus of this is to understand image augmentation well enough to do custom work.\n",
    "\n",
    "So don't worry as much about accuracy, worry more about adding augmentation to the existing method, \n",
    "understanding it, explaining it, and if it is significant enough, then trying to merge it into Keras.\n",
    "\n",
    "TASK DETAILS:\n",
    "Make a copy of:\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "Add functionality to ImageDataGenerator() beyond what is offered. You have flexibility here, one idea would be to add image histogram modification methods such as this: http://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html\n",
    "\n",
    "You are welcome to do anything you want related to ImageDataGenerator to make it better, but histogram modification could be a great starting point. With your work it helps to show before/after modifications in your notebook/blog. In the end this work is for you, to help give you visibility, so focus more on something that can be shared on LinkedIn rather than just a notebook. \n",
    "\n",
    "13 seconds per epoch on a 2 GHz Intel Core i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage import exposure, color\n",
    "from skimage import data, img_as_float\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data - CIFAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Parameters\n",
    "epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 64\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32   \n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()   \n",
    "\n",
    "# Only look at cats [=3] and dogs [=5]\n",
    "train_picks = np.ravel(np.logical_or(y_train==3,y_train==5))  \n",
    "test_picks = np.ravel(np.logical_or(y_test==3,y_test==5))     \n",
    "\n",
    "# Initialize training and test data corresponding to 3s and 5s\n",
    "y_train = np.array(y_train[train_picks]==5,dtype=int)\n",
    "y_test = np.array(y_test[test_picks]==5,dtype=int)\n",
    "\n",
    "x_train = x_train[train_picks]\n",
    "x_test = x_test[test_picks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess - Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert test and training data to Tensor\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(np.ravel(y_train), num_classes)\n",
    "y_test = keras.utils.to_categorical(np.ravel(y_test), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize test and training data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display Train and Test Sample Count\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define - ConvNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function - Contrast Adjustment Of Image Using CLAHE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_contrast_adjusment(img):\n",
    "    \n",
    "    # Convert pixel intensities to float value\n",
    "    img_start = img_as_float(img)\n",
    "\n",
    "    # Transorm image to HSV color spaace\n",
    "    img_hsv = color.rgb2hsv(img_start)\n",
    "\n",
    "    # Retrieve the value/brightness componenet of image\n",
    "    brightness = img_hsv[:,:,2]\n",
    "\n",
    "    # Apply CLAHE algorithm on brighntess component of image to adjust image contrast \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        b_adapteq = exposure.equalize_adapthist(brightness, clip_limit=0.03, nbins=48)\n",
    "\n",
    "    # Restore brighntess component subject to CLAHE to original HSV color space\n",
    "    img_hsv[:,:,2] = b_adapteq\n",
    "\n",
    "    # Convert image from HSV to RGB color space\n",
    "    img_end = color.hsv2rgb(img_hsv)\n",
    "    \n",
    "    return img_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmentation=True\n",
    "\n",
    "if augmentation==True:\n",
    "\n",
    "    # Data/Image Augmentation Parameters With CLAHE Algorithm\n",
    "    datagen = ImageDataGenerator(\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            rotation_range=40,\n",
    "            fill_mode='nearest',        \n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function = image_contrast_adjusment)\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    print(\"Running augmented training now, with augmentation\")\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "else:\n",
    "    print(\"Running regular training, no augmentation\")\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - Accuracy Of Convnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.epoch,history.history['val_acc'],'-o',label='validation')\n",
    "plt.plot(history.epoch,history.history['acc'],'-o',label='training')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
