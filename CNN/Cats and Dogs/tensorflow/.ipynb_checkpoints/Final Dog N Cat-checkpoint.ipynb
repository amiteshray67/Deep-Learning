{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "#importing necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for writing text files\n",
    "import glob\n",
    "import os     \n",
    "import random \n",
    "#reading images from a text file\n",
    "from tflearn.data_utils import image_preloader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = os.getcwd() + '\\\\images\\\\train'\n",
    "TEST_DATA = os.getcwd() + '\\\\images\\\\test_data.txt'\n",
    "TRAIN_DATA = os.getcwd() + '\\\\images\\\\training_data.txt'\n",
    "VALIDATION_DATA = os.getcwd()  + '\\\\images\\\\validation_data.txt'\n",
    "\n",
    "test_proportion=0.2\n",
    "train_proportion=0.8\n",
    "validation_proportion=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the image directories\n",
    "\n",
    "filenames_image = os.listdir(IMAGE_FOLDER)\n",
    "random.shuffle(filenames_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#total number of images\n",
    "\n",
    "total=len(filenames_image)\n",
    "\n",
    "##  *****training data******** \n",
    "fr = open(TRAIN_DATA, 'w')\n",
    "train_files=filenames_image[0: int(train_proportion*total)]\n",
    "for filename in train_files:\n",
    "    if filename[0:3] == 'cat':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 0\\n')\n",
    "    elif filename[0:3] == 'dog':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 1\\n')\n",
    "\n",
    "fr.close()\n",
    "\n",
    "##  *****testing data******** \n",
    "\n",
    "fr = open(TEST_DATA, 'w')\n",
    "test_files=filenames_image[int(math.ceil(train_proportion*total)):int(math.ceil((train_proportion+test_proportion)*total))]\n",
    "for filename in test_files:\n",
    "    if filename[0:3] == 'cat':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 0\\n')\n",
    "    elif filename[0:3] == 'dog':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 1\\n')\n",
    "fr.close()\n",
    "\n",
    "##  *****validation data******** \n",
    "fr = open(VALIDATION_DATA, 'w')\n",
    "valid_files=filenames_image[int(math.ceil((train_proportion+test_proportion)*total)):total]\n",
    "for filename in valid_files:\n",
    "    if filename[0:3] == 'cat':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 0\\n')\n",
    "    elif filename[0:3] == 'dog':\n",
    "        fr.write(IMAGE_FOLDER + '\\\\'+ filename + ' 1\\n')\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing data\n",
    "X_test, Y_test = image_preloader(TEST_DATA, image_shape=(100,100),mode='file', categorical_labels=True,normalize=True,grayscale=True)\n",
    "X_train, Y_train = image_preloader(TRAIN_DATA, image_shape=(100,100),mode='file', categorical_labels=True,normalize=True,grayscale=True)\n",
    "#X_val, Y_val = image_preloader(VALIDATION_DATA, image_shape=(64,64),mode='file', categorical_labels=True,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Number of training images 120\n",
      "Number of testing images 30\n",
      "Shape of an image (100, 100)\n",
      "Shape of label:(2,) ,number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print (\"Dataset\")\n",
    "print (\"Number of training images {}\".format(len(X_train)))\n",
    "print (\"Number of testing images {}\".format(len(X_test)))\n",
    "#print (\"Number of validation images {}\".format(len(X_val)))\n",
    "print (\"Shape of an image {}\" .format(X_train[1].shape))\n",
    "print (\"Shape of label:{} ,number of classes: {}\".format(Y_train[1].shape,len(Y_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# Image transformations\n",
    "###################################\n",
    "\n",
    "# normalisation of images\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Create extra synthetic training data by flipping & rotating images\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Architecture Design:\n",
      "\n",
      "x:  (?, 100, 100, 1)\n",
      "y:  (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Input Placeholder\n",
    "with tf.name_scope('input'):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None,100,100,1], name = 'x-input')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 2], name = 'y-output')\n",
    "    \n",
    "    tf.add_to_collection(tf.GraphKeys.INPUTS, x)\n",
    "    tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + '/' + 'x-input', x)\n",
    "\n",
    "    tf.add_to_collection(tf.GraphKeys.DATA_PREP, img_prep)\n",
    "    tf.add_to_collection(tf.GraphKeys.DATA_AUG, img_aug)\n",
    "       \n",
    "print(\"\\nArchitecture Design:\\n\")\n",
    "\n",
    "print(\"x: \", x.get_shape())\n",
    "print(\"y: \", y.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_1 Shape:  (?, 100, 100, 8)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 1\n",
    "with tf.name_scope('Convoltion_Layer_1'):   \n",
    "    \n",
    "    with tf.name_scope('weights_1'):\n",
    "        \n",
    "        W_conv1 = tf.truncated_normal([3, 3, 1, 8], stddev=0.1)\n",
    "        W_conv1 = tf.Variable(W_conv1)\n",
    "        \n",
    "        b_conv1 = tf.constant(0.1, shape=[8])\n",
    "        b_conv1 = tf.Variable(b_conv1)\n",
    "            \n",
    "    with tf.name_scope('input_reshape'):\n",
    "        x_image = tf.reshape(x, [-1,100,100,1])\n",
    "        \n",
    "    # Convolution 1\n",
    "    with tf.name_scope('Convolution_1'):       \n",
    "        h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') \n",
    "        h_conv1 = h_conv1 + b_conv1\n",
    "                    \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__1'):\n",
    "        activation_1 = tf.nn.relu(h_conv1)\n",
    "        \n",
    "    print(\"Conv_1 Shape: \" , activation_1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_2 Shape:  (?, 100, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 2\n",
    "with tf.name_scope('Convoltion_Layer_2'):   \n",
    "    \n",
    "    with tf.name_scope('weights_2'):\n",
    "        \n",
    "        W_conv2 = tf.truncated_normal([3, 3, 8, 16], stddev=0.1)\n",
    "        W_conv2 = tf.Variable(W_conv2)\n",
    "        \n",
    "        b_conv2 = tf.constant(0.1, shape=[16])\n",
    "        b_conv2 = tf.Variable(b_conv2)          \n",
    "        \n",
    "    # Convolution 2\n",
    "    with tf.name_scope('Convolution_2'):       \n",
    "        h_conv2 = tf.nn.conv2d(activation_1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') \n",
    "        h_conv2 = h_conv2 + b_conv2\n",
    "                    \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__2'):\n",
    "        activation_2 = tf.nn.relu(h_conv2)\n",
    "        \n",
    "    print(\"Conv_2 Shape: \" , activation_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool1 Shape:  (?, 50, 50, 16)\n"
     ]
    }
   ],
   "source": [
    "# Max Pooling Layer 1    \n",
    "with tf.name_scope('Max_Pooling_1'):\n",
    "    h_pool1 = tf.nn.max_pool(activation_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print(\"h_pool1 Shape: \" , h_pool1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_3 Shape:  (?, 50, 50, 16)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 3\n",
    "with tf.name_scope('Convolution_Layer_3'): \n",
    "    \n",
    "    with tf.name_scope('weights_3'):\n",
    "        W_conv3 = tf.truncated_normal([3, 3, 16, 16], stddev=0.1)\n",
    "        W_conv3 = tf.Variable(W_conv3)\n",
    "        \n",
    "        b_conv3 = tf.constant(0.1, shape=[16])\n",
    "        b_conv3 = tf.Variable(b_conv3)\n",
    "    \n",
    "    with tf.name_scope('Convolution_3'):\n",
    "        h_conv3 = tf.nn.conv2d(h_pool1, W_conv3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv3 = h_conv3 + b_conv3      \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__3'):\n",
    "        activation_3 = tf.nn.relu(h_conv3)\n",
    "        \n",
    "    print(\"Conv_3 Shape: \" , activation_3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_4 Shape:  (?, 50, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 4\n",
    "with tf.name_scope('Convolution_Layer_4'): \n",
    "    \n",
    "    with tf.name_scope('weights_4'):\n",
    "        W_conv4 = tf.truncated_normal([3, 3, 16, 64], stddev=0.1)\n",
    "        W_conv4 = tf.Variable(W_conv4)\n",
    "        \n",
    "        b_conv4 = tf.constant(0.1, shape=[64])\n",
    "        b_conv4 = tf.Variable(b_conv4)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_4'):\n",
    "        h_conv4 = tf.nn.conv2d(activation_3, W_conv4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv4 = h_conv4 + b_conv4       \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__4'):\n",
    "        activation_4 = tf.nn.relu(h_conv4)\n",
    "        \n",
    "    print(\"Conv_4 Shape: \" , activation_4.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool3 Shape:  (?, 25, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "# Sub Sampling    \n",
    "with tf.name_scope('Max_Pooling_2'):    \n",
    "    h_pool2 = tf.nn.max_pool(activation_4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print(\"h_pool3 Shape: \" , h_pool2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_5 Shape:  (?, 25, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 5\n",
    "with tf.name_scope('Convolution_Layer_5'): \n",
    "    \n",
    "    with tf.name_scope('weights_5'):\n",
    "        W_conv5 = tf.truncated_normal([3, 3, 64, 64], stddev=0.1)\n",
    "        W_conv5 = tf.Variable(W_conv5)\n",
    "        \n",
    "        b_conv5 = tf.constant(0.1, shape=[64])\n",
    "        b_conv5 = tf.Variable(b_conv5)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_5'):\n",
    "        h_conv5 = tf.nn.conv2d(h_pool2, W_conv5, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv5 = h_conv5 + b_conv5       \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__5'):\n",
    "        activation_5 = tf.nn.relu(h_conv5)\n",
    "        \n",
    "    print(\"Conv_5 Shape: \" , activation_5.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_6 Shape:  (?, 25, 25, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 6\n",
    "with tf.name_scope('Convolution_Layer_6'): \n",
    "    \n",
    "    with tf.name_scope('weights_6'):\n",
    "        W_conv6 = tf.truncated_normal([3, 3, 64, 32], stddev=0.1)\n",
    "        W_conv6 = tf.Variable(W_conv6)\n",
    "        \n",
    "        b_conv6 = tf.constant(0.1, shape=[32])\n",
    "        b_conv6 = tf.Variable(b_conv6)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_6'):\n",
    "        h_conv6 = tf.nn.conv2d(activation_5, W_conv6, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv6 = h_conv6 + b_conv6    \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__6'):\n",
    "        activation_6 = tf.nn.relu(h_conv6)\n",
    "        \n",
    "    print(\"Conv_6 Shape: \" , activation_6.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_7 Shape:  (?, 25, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 7\n",
    "with tf.name_scope('Convolution_Layer_7'): \n",
    "    \n",
    "    with tf.name_scope('weights_7'):\n",
    "        W_conv7 = tf.truncated_normal([3, 3, 32, 64], stddev=0.1)\n",
    "        W_conv7 = tf.Variable(W_conv7)\n",
    "        \n",
    "        b_conv7 = tf.constant(0.1, shape=[64])\n",
    "        b_conv7 = tf.Variable(b_conv7)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_7'):\n",
    "        h_conv7 = tf.nn.conv2d(activation_6, W_conv7, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv7 = h_conv7 + b_conv7      \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__7'):\n",
    "        activation_7 = tf.nn.relu(h_conv7)\n",
    "        \n",
    "    print(\"Conv_7 Shape: \" , activation_7.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool3 Shape:  (?, 13, 13, 32)\n"
     ]
    }
   ],
   "source": [
    "# Sub Sampling    \n",
    "with tf.name_scope('Max_Pooling_3'):    \n",
    "    h_pool3 = tf.nn.max_pool(activation_6, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print(\"h_pool3 Shape: \" , h_pool3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_8 Shape:  (?, 13, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 8\n",
    "with tf.name_scope('Convolution_Layer_8'): \n",
    "    \n",
    "    with tf.name_scope('weights_8'):\n",
    "        W_conv8 = tf.truncated_normal([3, 3, 32, 64], stddev=0.1)\n",
    "        W_conv8 = tf.Variable(W_conv8)\n",
    "        \n",
    "        b_conv8 = tf.constant(0.1, shape=[64])\n",
    "        b_conv8 = tf.Variable(b_conv8)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_8'):\n",
    "        h_conv8 = tf.nn.conv2d(h_pool3, W_conv8, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv8 = h_conv8 + b_conv8     \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__8'):\n",
    "        activation_8 = tf.nn.relu(h_conv8)\n",
    "        \n",
    "    print(\"Conv_8 Shape: \" , activation_8.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_9 Shape:  (?, 13, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 9\n",
    "with tf.name_scope('Convolution_Layer_9'): \n",
    "    \n",
    "    with tf.name_scope('weights_9'):\n",
    "        W_conv9 = tf.truncated_normal([3, 3, 64, 64], stddev=0.1)\n",
    "        W_conv9 = tf.Variable(W_conv9)\n",
    "        \n",
    "        b_conv9 = tf.constant(0.1, shape=[64])\n",
    "        b_conv9 = tf.Variable(b_conv9)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_9'):\n",
    "        h_conv9 = tf.nn.conv2d(activation_8, W_conv9, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv9 = h_conv8 + b_conv8     \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__9'):\n",
    "        activation_9 = tf.nn.relu(h_conv9)\n",
    "        \n",
    "    print(\"Conv_9 Shape: \" , activation_9.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_10 Shape:  (?, 13, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer 10\n",
    "with tf.name_scope('Convolution_Layer_10'): \n",
    "    \n",
    "    with tf.name_scope('weights_10'):\n",
    "        W_conv10 = tf.truncated_normal([3, 3, 64, 64], stddev=0.1)\n",
    "        W_conv10 = tf.Variable(W_conv10)\n",
    "        \n",
    "        b_conv10 = tf.constant(0.1, shape=[64])\n",
    "        b_conv10 = tf.Variable(b_conv10)\n",
    "    \n",
    "    with tf.name_scope('Convoltion_10'):\n",
    "        h_conv10 = tf.nn.conv2d(activation_9, W_conv10, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv10 = h_conv10 + b_conv10    \n",
    "        \n",
    "    # Activation\n",
    "    with tf.name_scope('ReLu__10'):\n",
    "        activation_10 = tf.nn.relu(h_conv10)\n",
    "        \n",
    "    print(\"Conv_10 Shape: \" , activation_10.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool4 Shape:  (?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# Sub Sampling    \n",
    "with tf.name_scope('Max_Pooling_4'):    \n",
    "    h_pool4 = tf.nn.max_pool(activation_10, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print(\"h_pool4 Shape: \" , h_pool4.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool_flat Shape:  (?, 3136)\n",
      "FC_1 Shape:  (?, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Fully Connected Layer\n",
    "with tf.name_scope('FC_1'):\n",
    "    \n",
    "    with tf.name_scope('weights_fc1'):\n",
    "        W_fc1 = tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1)\n",
    "        W_fc1 = tf.Variable(W_fc1)\n",
    "        \n",
    "        b_fc1 = tf.constant(0.1, shape=[1024])\n",
    "        b_fc1 = tf.Variable(b_fc1)\n",
    "    \n",
    "    with tf.name_scope('Un_Rolling'):    \n",
    "        h_pool_flat = tf.reshape(h_pool4, [-1, 7 * 7 * 64])\n",
    "        \n",
    "    print(\"h_pool_flat Shape: \" , h_pool_flat.get_shape())\n",
    "     \n",
    "    with tf.name_scope('weighted_sum'):\n",
    "        h_fc1 = tf.matmul(h_pool_flat, W_fc1) + b_fc1\n",
    "        \n",
    "    with tf.name_scope('ReLu_3'):\n",
    "        activation_fc1 = tf.nn.relu(h_fc1)\n",
    "        \n",
    "    print(\"FC_1 Shape: \" , activation_fc1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Out\n",
    "\n",
    "keep_prob = 0.7\n",
    "\n",
    "with tf.name_scope('Drop_Out'):\n",
    "    keep_prob = tf.placeholder(tf.float32, name='dropout-probability')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC_2 Shape:  (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Output Layer\n",
    "with tf.name_scope('FC_2'):\n",
    "    \n",
    "    with tf.name_scope('weights_fc2'):\n",
    "        W_fc2 = tf.truncated_normal([1024, 2], stddev=0.1)\n",
    "        W_fc2 = tf.Variable(W_fc2)\n",
    "        \n",
    "        b_fc2 = tf.constant(0.1, shape=[2])\n",
    "        b_fc2 = tf.Variable(b_fc2)\n",
    "\n",
    "    with tf.name_scope('weighted_sum'):\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        \n",
    "    print(\"FC_2 Shape: \" , y_conv.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find Cross Entropy\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y))\n",
    "\n",
    "# Train Model\n",
    "with tf.name_scope('train'):    \n",
    "    train_op = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Find Accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Log\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch=10000\n",
    "batch_size=20 \n",
    "previous_batch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Iteration no :0 , Accuracy:[0.60000002] , Loss : 2.8860957622528076\n",
      "Training: Iteration no :100 Loss : 0.9650125503540039\n",
      "Test: Iteration no :200 , Accuracy:[0.60000002] , Loss : 0.5433336496353149\n",
      "Training: Iteration no :300 Loss : 0.15580597519874573\n",
      "Test: Iteration no :400 , Accuracy:[0.53333336] , Loss : 0.052899815142154694\n",
      "Training: Iteration no :500 Loss : 0.03498990088701248\n",
      "Test: Iteration no :600 , Accuracy:[0.53333336] , Loss : 0.01319692749530077\n",
      "Training: Iteration no :700 Loss : 0.007739618420600891\n",
      "Test: Iteration no :800 , Accuracy:[0.53333336] , Loss : 0.013182222843170166\n",
      "Training: Iteration no :900 Loss : 0.0019599595107138157\n",
      "Test: Iteration no :1000 , Accuracy:[0.5] , Loss : 0.0019072297727689147\n",
      "Training: Iteration no :1100 Loss : 0.0031994536984711885\n",
      "Test: Iteration no :1200 , Accuracy:[0.5] , Loss : 0.001512950286269188\n",
      "Training: Iteration no :1300 Loss : 0.0030412052292376757\n",
      "Test: Iteration no :1400 , Accuracy:[0.46666667] , Loss : 0.0018972133984789252\n",
      "Training: Iteration no :1500 Loss : 0.0003782582061830908\n",
      "Test: Iteration no :1600 , Accuracy:[0.46666667] , Loss : 0.0006031148368492723\n",
      "Training: Iteration no :1700 Loss : 0.0006728431326337159\n",
      "Test: Iteration no :1800 , Accuracy:[0.46666667] , Loss : 0.0005080796545371413\n",
      "Training: Iteration no :1900 Loss : 0.0005672014085575938\n",
      "Test: Iteration no :2000 , Accuracy:[0.46666667] , Loss : 0.00043923911289311945\n",
      "Training: Iteration no :2100 Loss : 0.0002718757896218449\n",
      "Test: Iteration no :2200 , Accuracy:[0.46666667] , Loss : 0.0005480788531713188\n",
      "Training: Iteration no :2300 Loss : 0.0003872229717671871\n",
      "Test: Iteration no :2400 , Accuracy:[0.46666667] , Loss : 0.0002492377534508705\n",
      "Training: Iteration no :2500 Loss : 0.00013284236774779856\n",
      "Test: Iteration no :2600 , Accuracy:[0.46666667] , Loss : 0.0002090379857691005\n",
      "Training: Iteration no :2700 Loss : 0.00012180203339084983\n",
      "Test: Iteration no :2800 , Accuracy:[0.46666667] , Loss : 0.00015819832333363593\n",
      "Training: Iteration no :2900 Loss : 0.00010538737842580304\n",
      "Test: Iteration no :3000 , Accuracy:[0.46666667] , Loss : 6.249012221815065e-05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        \n",
    "    #test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "    #train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "\n",
    "    tf.global_variables_initializer().run()    \n",
    "\n",
    "    for i in range(epoch+1):\n",
    "\n",
    "        #batch wise training \n",
    "        if previous_batch >= len(X_train) : #total --> total number of training images\n",
    "            previous_batch=0    \n",
    "\n",
    "        current_batch=previous_batch+batch_size\n",
    "\n",
    "        x_input=X_train[previous_batch:current_batch]        \n",
    "        x_images=np.reshape(x_input,[batch_size,100,100,1])\n",
    "\n",
    "        y_input=Y_train[previous_batch:current_batch]\n",
    "        y_label=np.reshape(y_input,[batch_size,2])\n",
    "\n",
    "        previous_batch=previous_batch+batch_size\n",
    "\n",
    "        _,loss=sess.run([train_op, cross_entropy], feed_dict={x: x_images, y: y_label, keep_prob: 0.9}) \n",
    "\n",
    "        if i% 200==0:\n",
    "\n",
    "            n=30  \n",
    "            x_test_images=np.reshape(X_test[0:n],[n,100,100,1])\n",
    "            y_test_labels=np.reshape(Y_test[0:n],[n,2])\n",
    "\n",
    "            Accuracy=sess.run([accuracy],\n",
    "                               feed_dict={\n",
    "                            x: x_test_images ,\n",
    "                            y: y_test_labels, keep_prob: 1\n",
    "                          })\n",
    "            print (\"Test: Iteration no :{} , Accuracy:{} , Loss : {}\" .format(i,Accuracy,loss))\n",
    "\n",
    "        elif (i % 100) == 0:   \n",
    "            print (\"Training: Iteration no :{} Loss : {}\" .format(i,loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
